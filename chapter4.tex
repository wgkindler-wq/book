\chapter{Differentiation in Multivariable Spaces}

\section{Lecture Notes: The Total Derivative}

\subsection{Definition of Differentiability}
Let $f: U \to \mathbb{R}^m$ be a function defined on an open set $U \subseteq \mathbb{R}^n$.
\begin{definition}[Differentiability]
We say $f$ is \textbf{differentiable} at a point $x_0 \in U$ if there exists a linear transformation $L: \mathbb{R}^n \to \mathbb{R}^m$ such that:
\[ \lim_{h \to 0} \frac{\|f(x_0 + h) - f(x_0) - L(h)\|}{\|h\|} = 0 \]
Using asymptotic notation, this is equivalent to:
\[ f(x_0 + h) = f(x_0) + L(h) + o(\|h\|) \quad (\text{as } h \to 0) \]
The linear map $L$ is unique and is denoted by $Df(x_0)$ or $f'(x_0)$.
\end{definition}

\subsection{Partial Derivatives}
\begin{definition}[Partial Derivative]
The $i$-th partial derivative of $f$ at $x$ is the derivative of the partial function obtained by fixing all variables except $x_i$:
\[ \frac{\partial f}{\partial x_i}(x) = \lim_{t \to 0} \frac{f(x + t e_i) - f(x)}{t} \]
where $e_i$ is the $i$-th standard basis vector.
\end{definition}

\subsection{The Gradient}
If $f: U \to \mathbb{R}$ is differentiable at $x$, then the matrix of the linear map $f'(x)$ (with respect to the standard basis) is a row vector:
\[ f'(x) = \begin{pmatrix} \frac{\partial f}{\partial x_1}(x) & \dots & \frac{\partial f}{\partial x_n}(x) \end{pmatrix} \]
The \textbf{gradient} of $f$, denoted $\nabla f(x)$, is the corresponding column vector:
\[ \nabla f(x) = \left( \frac{\partial f}{\partial x_1}(x), \dots, \frac{\partial f}{\partial x_n}(x) \right)^T \]
The relationship with the directional derivative is given by the inner product:
\[ f'(x)(v) = \langle \nabla f(x), v \rangle \]

\section{Recitation Notes: Theorems and Examples}

\subsection{Differentiability and Partial Derivatives}
\begin{theorem}
If $f$ is differentiable at $x$, then all partial derivatives exist at $x$.
The converse is \textbf{false}. Existence of partial derivatives does not guarantee differentiability.
\end{theorem}

\begin{theorem}[$C^1$ Condition]
If all partial derivatives $\frac{\partial f}{\partial x_i}$ exist and are \textbf{continuous} in a neighborhood of $x$, then $f$ is differentiable at $x$.
\end{theorem}

\subsection{Properties}
\begin{theorem}
If $f$ is differentiable at $x$, then $f$ is continuous at $x$.
\end{theorem}

\begin{theorem}[Chain Rule]
Let $f: \mathbb{R}^n \to \mathbb{R}^m$ be differentiable at $x$, and $g: \mathbb{R}^m \to \mathbb{R}^k$ be differentiable at $y = f(x)$. Then $g \circ f$ is differentiable at $x$, and:
\[ D(g \circ f)(x) = Dg(f(x)) \circ Df(x) \]
In terms of Jacobian matrices, this is matrix multiplication.
\end{theorem}

\subsection{Example}
Consider $f(x, y) = \begin{cases} \frac{x^3}{x^2+y^2} & (x, y) \ne (0, 0) \\ 0 & (x, y) = (0, 0) \end{cases}$.
\begin{enumerate}
    \item \textbf{Continuity:} Note that $|\frac{x^3}{x^2+y^2}| = |x| \frac{x^2}{x^2+y^2} \le |x|$. As $(x, y) \to 0$, $|x| \to 0$, so $f$ is continuous.
    \item \textbf{Partial Derivatives:} $f(x, 0) = x$, so $\partial_x f(0, 0) = 1$. $f(0, y) = 0$, so $\partial_y f(0, 0) = 0$.
    \item \textbf{Differentiability:} Candidate for linear approx is $L(h_1, h_2) = 1 \cdot h_1 + 0 \cdot h_2 = h_1$.
    Check limit:
    \[ \frac{|f(h_1, h_2) - f(0, 0) - L(h_1, h_2)|}{\sqrt{h_1^2+h_2^2}} = \frac{|\frac{h_1^3}{h_1^2+h_2^2} - h_1|}{\sqrt{h_1^2+h_2^2}} = \frac{|h_1^3 - h_1^3 - h_1 h_2^2|}{(h_1^2+h_2^2)^{3/2}} = \frac{|h_1 h_2^2|}{(h_1^2+h_2^2)^{3/2}} \]
    Take path $h_1 = h_2 = t$:
    \[ \frac{|t^3|}{(2t^2)^{3/2}} = \frac{|t|^3}{2\sqrt{2}|t|^3} = \frac{1}{2\sqrt{2}} \ne 0 \]
    So $f$ is \textbf{not} differentiable at $(0, 0)$.
\end{enumerate}
